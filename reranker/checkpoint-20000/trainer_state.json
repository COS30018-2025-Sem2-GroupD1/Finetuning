{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8356182269225747,
  "eval_steps": 500,
  "global_step": 20000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002089045567306437,
      "grad_norm": 0.8724204897880554,
      "learning_rate": 8.35421888053467e-07,
      "loss": 1.9004,
      "step": 50
    },
    {
      "epoch": 0.004178091134612874,
      "grad_norm": 0.7522647976875305,
      "learning_rate": 1.670843776106934e-06,
      "loss": 1.9266,
      "step": 100
    },
    {
      "epoch": 0.00626713670191931,
      "grad_norm": 0.9465087652206421,
      "learning_rate": 2.506265664160401e-06,
      "loss": 1.8159,
      "step": 150
    },
    {
      "epoch": 0.008356182269225748,
      "grad_norm": 2.0452184677124023,
      "learning_rate": 3.341687552213868e-06,
      "loss": 1.4922,
      "step": 200
    },
    {
      "epoch": 0.010445227836532185,
      "grad_norm": 1.3516603708267212,
      "learning_rate": 4.177109440267335e-06,
      "loss": 0.9825,
      "step": 250
    },
    {
      "epoch": 0.01253427340383862,
      "grad_norm": 0.799002468585968,
      "learning_rate": 5.012531328320802e-06,
      "loss": 0.3705,
      "step": 300
    },
    {
      "epoch": 0.014623318971145058,
      "grad_norm": 0.2245427370071411,
      "learning_rate": 5.847953216374269e-06,
      "loss": 0.1221,
      "step": 350
    },
    {
      "epoch": 0.016712364538451496,
      "grad_norm": 0.16111983358860016,
      "learning_rate": 6.683375104427736e-06,
      "loss": 0.0556,
      "step": 400
    },
    {
      "epoch": 0.01880141010575793,
      "grad_norm": 0.02748023346066475,
      "learning_rate": 7.518796992481203e-06,
      "loss": 0.0392,
      "step": 450
    },
    {
      "epoch": 0.02089045567306437,
      "grad_norm": 0.1108013391494751,
      "learning_rate": 8.35421888053467e-06,
      "loss": 0.0273,
      "step": 500
    },
    {
      "epoch": 0.022979501240370806,
      "grad_norm": 0.0038579157553613186,
      "learning_rate": 9.189640768588137e-06,
      "loss": 0.0127,
      "step": 550
    },
    {
      "epoch": 0.02506854680767724,
      "grad_norm": 0.07367505878210068,
      "learning_rate": 1.0025062656641604e-05,
      "loss": 0.018,
      "step": 600
    },
    {
      "epoch": 0.02715759237498368,
      "grad_norm": 0.036454640328884125,
      "learning_rate": 1.0860484544695072e-05,
      "loss": 0.0159,
      "step": 650
    },
    {
      "epoch": 0.029246637942290116,
      "grad_norm": 0.2696688175201416,
      "learning_rate": 1.1695906432748539e-05,
      "loss": 0.0117,
      "step": 700
    },
    {
      "epoch": 0.031335683509596556,
      "grad_norm": 0.0009579132311046124,
      "learning_rate": 1.2531328320802006e-05,
      "loss": 0.0127,
      "step": 750
    },
    {
      "epoch": 0.03342472907690299,
      "grad_norm": 0.007336754817515612,
      "learning_rate": 1.3366750208855472e-05,
      "loss": 0.0071,
      "step": 800
    },
    {
      "epoch": 0.03551377464420943,
      "grad_norm": 0.4338447153568268,
      "learning_rate": 1.4202172096908939e-05,
      "loss": 0.0033,
      "step": 850
    },
    {
      "epoch": 0.03760282021151586,
      "grad_norm": 0.0005747616523876786,
      "learning_rate": 1.5037593984962406e-05,
      "loss": 0.0059,
      "step": 900
    },
    {
      "epoch": 0.0396918657788223,
      "grad_norm": 0.0047984435223042965,
      "learning_rate": 1.5873015873015872e-05,
      "loss": 0.0059,
      "step": 950
    },
    {
      "epoch": 0.04178091134612874,
      "grad_norm": 0.011633168905973434,
      "learning_rate": 1.670843776106934e-05,
      "loss": 0.0153,
      "step": 1000
    },
    {
      "epoch": 0.043869956913435176,
      "grad_norm": 0.019145438447594643,
      "learning_rate": 1.754385964912281e-05,
      "loss": 0.0108,
      "step": 1050
    },
    {
      "epoch": 0.04595900248074161,
      "grad_norm": 0.06296111643314362,
      "learning_rate": 1.8379281537176274e-05,
      "loss": 0.0056,
      "step": 1100
    },
    {
      "epoch": 0.04804804804804805,
      "grad_norm": 0.001881525618955493,
      "learning_rate": 1.9214703425229743e-05,
      "loss": 0.0053,
      "step": 1150
    },
    {
      "epoch": 0.05013709361535448,
      "grad_norm": 0.00016400111780967563,
      "learning_rate": 1.9997361129436605e-05,
      "loss": 0.0075,
      "step": 1200
    },
    {
      "epoch": 0.05222613918266092,
      "grad_norm": 0.0022410335950553417,
      "learning_rate": 1.9953379953379953e-05,
      "loss": 0.004,
      "step": 1250
    },
    {
      "epoch": 0.05431518474996736,
      "grad_norm": 0.24593693017959595,
      "learning_rate": 1.990939877732331e-05,
      "loss": 0.0019,
      "step": 1300
    },
    {
      "epoch": 0.0564042303172738,
      "grad_norm": 1.0619845390319824,
      "learning_rate": 1.9865417601266657e-05,
      "loss": 0.0077,
      "step": 1350
    },
    {
      "epoch": 0.05849327588458023,
      "grad_norm": 0.32764098048210144,
      "learning_rate": 1.9821436425210012e-05,
      "loss": 0.0023,
      "step": 1400
    },
    {
      "epoch": 0.06058232145188667,
      "grad_norm": 0.09603584557771683,
      "learning_rate": 1.9777455249153364e-05,
      "loss": 0.0039,
      "step": 1450
    },
    {
      "epoch": 0.06267136701919311,
      "grad_norm": 0.0012794353533536196,
      "learning_rate": 1.9733474073096716e-05,
      "loss": 0.0056,
      "step": 1500
    },
    {
      "epoch": 0.06476041258649955,
      "grad_norm": 0.0019687882158905268,
      "learning_rate": 1.9689492897040068e-05,
      "loss": 0.0017,
      "step": 1550
    },
    {
      "epoch": 0.06684945815380598,
      "grad_norm": 1.227808570547495e-05,
      "learning_rate": 1.964551172098342e-05,
      "loss": 0.0047,
      "step": 1600
    },
    {
      "epoch": 0.06893850372111242,
      "grad_norm": 0.0013216919032856822,
      "learning_rate": 1.9601530544926772e-05,
      "loss": 0.0097,
      "step": 1650
    },
    {
      "epoch": 0.07102754928841885,
      "grad_norm": 0.00020272204710636288,
      "learning_rate": 1.9557549368870127e-05,
      "loss": 0.0015,
      "step": 1700
    },
    {
      "epoch": 0.07311659485572529,
      "grad_norm": 0.0004067678819410503,
      "learning_rate": 1.9513568192813476e-05,
      "loss": 0.0131,
      "step": 1750
    },
    {
      "epoch": 0.07520564042303172,
      "grad_norm": 0.00038819247856736183,
      "learning_rate": 1.946958701675683e-05,
      "loss": 0.0011,
      "step": 1800
    },
    {
      "epoch": 0.07729468599033816,
      "grad_norm": 0.0005490116309374571,
      "learning_rate": 1.9425605840700183e-05,
      "loss": 0.0035,
      "step": 1850
    },
    {
      "epoch": 0.0793837315576446,
      "grad_norm": 0.21484333276748657,
      "learning_rate": 1.9381624664643535e-05,
      "loss": 0.0079,
      "step": 1900
    },
    {
      "epoch": 0.08147277712495103,
      "grad_norm": 0.409699946641922,
      "learning_rate": 1.9337643488586887e-05,
      "loss": 0.0052,
      "step": 1950
    },
    {
      "epoch": 0.08356182269225748,
      "grad_norm": 0.00017914619820658118,
      "learning_rate": 1.929366231253024e-05,
      "loss": 0.001,
      "step": 2000
    },
    {
      "epoch": 0.08565086825956392,
      "grad_norm": 3.495971759548411e-05,
      "learning_rate": 1.924968113647359e-05,
      "loss": 0.0027,
      "step": 2050
    },
    {
      "epoch": 0.08773991382687035,
      "grad_norm": 0.0012844093143939972,
      "learning_rate": 1.9206579583938076e-05,
      "loss": 0.0035,
      "step": 2100
    },
    {
      "epoch": 0.08982895939417679,
      "grad_norm": 6.082055188016966e-05,
      "learning_rate": 1.9162598407881428e-05,
      "loss": 0.004,
      "step": 2150
    },
    {
      "epoch": 0.09191800496148322,
      "grad_norm": 0.0006079302984289825,
      "learning_rate": 1.911861723182478e-05,
      "loss": 0.0056,
      "step": 2200
    },
    {
      "epoch": 0.09400705052878966,
      "grad_norm": 0.08007634431123734,
      "learning_rate": 1.907463605576813e-05,
      "loss": 0.0017,
      "step": 2250
    },
    {
      "epoch": 0.0960960960960961,
      "grad_norm": 9.49065070017241e-05,
      "learning_rate": 1.9030654879711487e-05,
      "loss": 0.0033,
      "step": 2300
    },
    {
      "epoch": 0.09818514166340253,
      "grad_norm": 0.00034756259992718697,
      "learning_rate": 1.8986673703654835e-05,
      "loss": 0.0139,
      "step": 2350
    },
    {
      "epoch": 0.10027418723070897,
      "grad_norm": 0.06892730295658112,
      "learning_rate": 1.894269252759819e-05,
      "loss": 0.0013,
      "step": 2400
    },
    {
      "epoch": 0.1023632327980154,
      "grad_norm": 0.0008113022777251899,
      "learning_rate": 1.8898711351541542e-05,
      "loss": 0.0059,
      "step": 2450
    },
    {
      "epoch": 0.10445227836532184,
      "grad_norm": 0.030839858576655388,
      "learning_rate": 1.8854730175484894e-05,
      "loss": 0.0047,
      "step": 2500
    },
    {
      "epoch": 0.10654132393262829,
      "grad_norm": 0.00027324637630954385,
      "learning_rate": 1.8810748999428246e-05,
      "loss": 0.0048,
      "step": 2550
    },
    {
      "epoch": 0.10863036949993472,
      "grad_norm": 0.029352687299251556,
      "learning_rate": 1.8766767823371598e-05,
      "loss": 0.0135,
      "step": 2600
    },
    {
      "epoch": 0.11071941506724116,
      "grad_norm": 0.007341902237385511,
      "learning_rate": 1.872278664731495e-05,
      "loss": 0.0019,
      "step": 2650
    },
    {
      "epoch": 0.1128084606345476,
      "grad_norm": 9.914075781125575e-05,
      "learning_rate": 1.86788054712583e-05,
      "loss": 0.0008,
      "step": 2700
    },
    {
      "epoch": 0.11489750620185403,
      "grad_norm": 0.0121819619089365,
      "learning_rate": 1.8634824295201654e-05,
      "loss": 0.0048,
      "step": 2750
    },
    {
      "epoch": 0.11698655176916047,
      "grad_norm": 0.12612377107143402,
      "learning_rate": 1.859084311914501e-05,
      "loss": 0.0022,
      "step": 2800
    },
    {
      "epoch": 0.1190755973364669,
      "grad_norm": 1.0733606815338135,
      "learning_rate": 1.8546861943088357e-05,
      "loss": 0.0039,
      "step": 2850
    },
    {
      "epoch": 0.12116464290377334,
      "grad_norm": 1.2771921547027887e-06,
      "learning_rate": 1.8502880767031713e-05,
      "loss": 0.0032,
      "step": 2900
    },
    {
      "epoch": 0.12325368847107977,
      "grad_norm": 0.0033693849109113216,
      "learning_rate": 1.8458899590975065e-05,
      "loss": 0.0035,
      "step": 2950
    },
    {
      "epoch": 0.12534273403838622,
      "grad_norm": 2.934782241936773e-05,
      "learning_rate": 1.8414918414918416e-05,
      "loss": 0.0017,
      "step": 3000
    },
    {
      "epoch": 0.12743177960569266,
      "grad_norm": 3.1420921004610136e-05,
      "learning_rate": 1.8370937238861768e-05,
      "loss": 0.0016,
      "step": 3050
    },
    {
      "epoch": 0.1295208251729991,
      "grad_norm": 0.0404394194483757,
      "learning_rate": 1.832695606280512e-05,
      "loss": 0.0029,
      "step": 3100
    },
    {
      "epoch": 0.13160987074030553,
      "grad_norm": 0.000595349702052772,
      "learning_rate": 1.8282974886748472e-05,
      "loss": 0.0021,
      "step": 3150
    },
    {
      "epoch": 0.13369891630761196,
      "grad_norm": 1.2920484095957363e-06,
      "learning_rate": 1.8238993710691827e-05,
      "loss": 0.0031,
      "step": 3200
    },
    {
      "epoch": 0.1357879618749184,
      "grad_norm": 0.0002439052623230964,
      "learning_rate": 1.8195012534635176e-05,
      "loss": 0.0003,
      "step": 3250
    },
    {
      "epoch": 0.13787700744222484,
      "grad_norm": 0.0001760345621732995,
      "learning_rate": 1.815103135857853e-05,
      "loss": 0.002,
      "step": 3300
    },
    {
      "epoch": 0.13996605300953127,
      "grad_norm": 9.923019916868725e-08,
      "learning_rate": 1.8107050182521883e-05,
      "loss": 0.0002,
      "step": 3350
    },
    {
      "epoch": 0.1420550985768377,
      "grad_norm": 2.5995871055783937e-06,
      "learning_rate": 1.8063069006465235e-05,
      "loss": 0.0015,
      "step": 3400
    },
    {
      "epoch": 0.14414414414414414,
      "grad_norm": 0.00016821097233332694,
      "learning_rate": 1.8019087830408587e-05,
      "loss": 0.0038,
      "step": 3450
    },
    {
      "epoch": 0.14623318971145058,
      "grad_norm": 0.00046732366899959743,
      "learning_rate": 1.797510665435194e-05,
      "loss": 0.0139,
      "step": 3500
    },
    {
      "epoch": 0.14832223527875701,
      "grad_norm": 2.8456741347326897e-05,
      "learning_rate": 1.793112547829529e-05,
      "loss": 0.0006,
      "step": 3550
    },
    {
      "epoch": 0.15041128084606345,
      "grad_norm": 0.08496873825788498,
      "learning_rate": 1.7887144302238642e-05,
      "loss": 0.0081,
      "step": 3600
    },
    {
      "epoch": 0.15250032641336989,
      "grad_norm": 0.0005794467870146036,
      "learning_rate": 1.7843163126181994e-05,
      "loss": 0.0031,
      "step": 3650
    },
    {
      "epoch": 0.15458937198067632,
      "grad_norm": 1.4053376617084723e-05,
      "learning_rate": 1.779918195012535e-05,
      "loss": 0.0007,
      "step": 3700
    },
    {
      "epoch": 0.15667841754798276,
      "grad_norm": 0.0010423845378682017,
      "learning_rate": 1.7755200774068698e-05,
      "loss": 0.0093,
      "step": 3750
    },
    {
      "epoch": 0.1587674631152892,
      "grad_norm": 0.541858971118927,
      "learning_rate": 1.7711219598012053e-05,
      "loss": 0.0025,
      "step": 3800
    },
    {
      "epoch": 0.16085650868259563,
      "grad_norm": 0.0002220713795395568,
      "learning_rate": 1.7667238421955405e-05,
      "loss": 0.0077,
      "step": 3850
    },
    {
      "epoch": 0.16294555424990206,
      "grad_norm": 0.0003600392956286669,
      "learning_rate": 1.7623257245898757e-05,
      "loss": 0.0013,
      "step": 3900
    },
    {
      "epoch": 0.1650345998172085,
      "grad_norm": 6.035270416759886e-05,
      "learning_rate": 1.757927606984211e-05,
      "loss": 0.004,
      "step": 3950
    },
    {
      "epoch": 0.16712364538451496,
      "grad_norm": 0.00026328410604037344,
      "learning_rate": 1.753529489378546e-05,
      "loss": 0.0007,
      "step": 4000
    },
    {
      "epoch": 0.1692126909518214,
      "grad_norm": 0.0004203234857413918,
      "learning_rate": 1.7491313717728813e-05,
      "loss": 0.0062,
      "step": 4050
    },
    {
      "epoch": 0.17130173651912783,
      "grad_norm": 0.0005666267243213952,
      "learning_rate": 1.7447332541672165e-05,
      "loss": 0.007,
      "step": 4100
    },
    {
      "epoch": 0.17339078208643427,
      "grad_norm": 0.006465775892138481,
      "learning_rate": 1.7403351365615517e-05,
      "loss": 0.0032,
      "step": 4150
    },
    {
      "epoch": 0.1754798276537407,
      "grad_norm": 2.791521001199726e-05,
      "learning_rate": 1.7359370189558872e-05,
      "loss": 0.0027,
      "step": 4200
    },
    {
      "epoch": 0.17756887322104714,
      "grad_norm": 0.11890717595815659,
      "learning_rate": 1.731538901350222e-05,
      "loss": 0.0009,
      "step": 4250
    },
    {
      "epoch": 0.17965791878835358,
      "grad_norm": 2.010086791415233e-05,
      "learning_rate": 1.7271407837445576e-05,
      "loss": 0.0036,
      "step": 4300
    },
    {
      "epoch": 0.18174696435566,
      "grad_norm": 0.00018441351130604744,
      "learning_rate": 1.7227426661388928e-05,
      "loss": 0.0002,
      "step": 4350
    },
    {
      "epoch": 0.18383600992296645,
      "grad_norm": 1.1776895007642452e-05,
      "learning_rate": 1.718344548533228e-05,
      "loss": 0.006,
      "step": 4400
    },
    {
      "epoch": 0.18592505549027288,
      "grad_norm": 0.0007693985244259238,
      "learning_rate": 1.713946430927563e-05,
      "loss": 0.0016,
      "step": 4450
    },
    {
      "epoch": 0.18801410105757932,
      "grad_norm": 0.00022103014634922147,
      "learning_rate": 1.7095483133218983e-05,
      "loss": 0.0073,
      "step": 4500
    },
    {
      "epoch": 0.19010314662488575,
      "grad_norm": 0.0027514679823070765,
      "learning_rate": 1.7051501957162335e-05,
      "loss": 0.0086,
      "step": 4550
    },
    {
      "epoch": 0.1921921921921922,
      "grad_norm": 0.024037031456828117,
      "learning_rate": 1.7007520781105687e-05,
      "loss": 0.0032,
      "step": 4600
    },
    {
      "epoch": 0.19428123775949863,
      "grad_norm": 0.010657952167093754,
      "learning_rate": 1.696353960504904e-05,
      "loss": 0.0027,
      "step": 4650
    },
    {
      "epoch": 0.19637028332680506,
      "grad_norm": 0.0002244272909592837,
      "learning_rate": 1.6919558428992394e-05,
      "loss": 0.0033,
      "step": 4700
    },
    {
      "epoch": 0.1984593288941115,
      "grad_norm": 5.923783828620799e-05,
      "learning_rate": 1.6875577252935743e-05,
      "loss": 0.0012,
      "step": 4750
    },
    {
      "epoch": 0.20054837446141793,
      "grad_norm": 0.00012022606824757531,
      "learning_rate": 1.6831596076879098e-05,
      "loss": 0.002,
      "step": 4800
    },
    {
      "epoch": 0.20263742002872437,
      "grad_norm": 0.14758417010307312,
      "learning_rate": 1.678761490082245e-05,
      "loss": 0.0041,
      "step": 4850
    },
    {
      "epoch": 0.2047264655960308,
      "grad_norm": 0.07693017274141312,
      "learning_rate": 1.67436337247658e-05,
      "loss": 0.0058,
      "step": 4900
    },
    {
      "epoch": 0.20681551116333724,
      "grad_norm": 0.16263704001903534,
      "learning_rate": 1.6699652548709154e-05,
      "loss": 0.0068,
      "step": 4950
    },
    {
      "epoch": 0.20890455673064368,
      "grad_norm": 7.014587754383683e-05,
      "learning_rate": 1.6655671372652505e-05,
      "loss": 0.0002,
      "step": 5000
    },
    {
      "epoch": 0.2109936022979501,
      "grad_norm": 2.908557235059561e-06,
      "learning_rate": 1.6611690196595857e-05,
      "loss": 0.0008,
      "step": 5050
    },
    {
      "epoch": 0.21308264786525657,
      "grad_norm": 0.14426229894161224,
      "learning_rate": 1.6567709020539213e-05,
      "loss": 0.01,
      "step": 5100
    },
    {
      "epoch": 0.215171693432563,
      "grad_norm": 0.7804872393608093,
      "learning_rate": 1.652372784448256e-05,
      "loss": 0.0059,
      "step": 5150
    },
    {
      "epoch": 0.21726073899986945,
      "grad_norm": 0.001103077083826065,
      "learning_rate": 1.6479746668425916e-05,
      "loss": 0.0034,
      "step": 5200
    },
    {
      "epoch": 0.21934978456717588,
      "grad_norm": 5.867925210623071e-06,
      "learning_rate": 1.6435765492369268e-05,
      "loss": 0.002,
      "step": 5250
    },
    {
      "epoch": 0.22143883013448232,
      "grad_norm": 1.9886870177288074e-06,
      "learning_rate": 1.639178431631262e-05,
      "loss": 0.0023,
      "step": 5300
    },
    {
      "epoch": 0.22352787570178875,
      "grad_norm": 1.852719287853688e-05,
      "learning_rate": 1.6348682763777105e-05,
      "loss": 0.0089,
      "step": 5350
    },
    {
      "epoch": 0.2256169212690952,
      "grad_norm": 0.008278877474367619,
      "learning_rate": 1.6304701587720457e-05,
      "loss": 0.0001,
      "step": 5400
    },
    {
      "epoch": 0.22770596683640162,
      "grad_norm": 0.00047150315367616713,
      "learning_rate": 1.626072041166381e-05,
      "loss": 0.0041,
      "step": 5450
    },
    {
      "epoch": 0.22979501240370806,
      "grad_norm": 8.18861906282109e-07,
      "learning_rate": 1.6217618859128294e-05,
      "loss": 0.0073,
      "step": 5500
    },
    {
      "epoch": 0.2318840579710145,
      "grad_norm": 3.802021819865331e-05,
      "learning_rate": 1.6173637683071646e-05,
      "loss": 0.0006,
      "step": 5550
    },
    {
      "epoch": 0.23397310353832093,
      "grad_norm": 9.293727634940296e-05,
      "learning_rate": 1.6129656507014998e-05,
      "loss": 0.0056,
      "step": 5600
    },
    {
      "epoch": 0.23606214910562737,
      "grad_norm": 0.0005817569326609373,
      "learning_rate": 1.608567533095835e-05,
      "loss": 0.004,
      "step": 5650
    },
    {
      "epoch": 0.2381511946729338,
      "grad_norm": 0.011069594882428646,
      "learning_rate": 1.6041694154901702e-05,
      "loss": 0.0027,
      "step": 5700
    },
    {
      "epoch": 0.24024024024024024,
      "grad_norm": 0.0004940230865031481,
      "learning_rate": 1.5997712978845054e-05,
      "loss": 0.0061,
      "step": 5750
    },
    {
      "epoch": 0.24232928580754667,
      "grad_norm": 0.12139755487442017,
      "learning_rate": 1.595373180278841e-05,
      "loss": 0.0022,
      "step": 5800
    },
    {
      "epoch": 0.2444183313748531,
      "grad_norm": 0.4207569360733032,
      "learning_rate": 1.5909750626731758e-05,
      "loss": 0.0048,
      "step": 5850
    },
    {
      "epoch": 0.24650737694215955,
      "grad_norm": 7.011315119598294e-06,
      "learning_rate": 1.5865769450675113e-05,
      "loss": 0.0028,
      "step": 5900
    },
    {
      "epoch": 0.24859642250946598,
      "grad_norm": 0.0025441283360123634,
      "learning_rate": 1.5821788274618465e-05,
      "loss": 0.0068,
      "step": 5950
    },
    {
      "epoch": 0.25068546807677244,
      "grad_norm": 0.0004624749126378447,
      "learning_rate": 1.5777807098561817e-05,
      "loss": 0.0025,
      "step": 6000
    },
    {
      "epoch": 0.2527745136440789,
      "grad_norm": 1.3017305718676653e-05,
      "learning_rate": 1.573382592250517e-05,
      "loss": 0.0032,
      "step": 6050
    },
    {
      "epoch": 0.2548635592113853,
      "grad_norm": 1.3409040548140183e-05,
      "learning_rate": 1.568984474644852e-05,
      "loss": 0.0001,
      "step": 6100
    },
    {
      "epoch": 0.25695260477869175,
      "grad_norm": 0.24569058418273926,
      "learning_rate": 1.5645863570391872e-05,
      "loss": 0.004,
      "step": 6150
    },
    {
      "epoch": 0.2590416503459982,
      "grad_norm": 0.006109262816607952,
      "learning_rate": 1.5601882394335228e-05,
      "loss": 0.0039,
      "step": 6200
    },
    {
      "epoch": 0.2611306959133046,
      "grad_norm": 0.00024466635659337044,
      "learning_rate": 1.5557901218278576e-05,
      "loss": 0.0027,
      "step": 6250
    },
    {
      "epoch": 0.26321974148061106,
      "grad_norm": 0.2788088619709015,
      "learning_rate": 1.551392004222193e-05,
      "loss": 0.0025,
      "step": 6300
    },
    {
      "epoch": 0.2653087870479175,
      "grad_norm": 6.483202923845965e-06,
      "learning_rate": 1.5469938866165283e-05,
      "loss": 0.0021,
      "step": 6350
    },
    {
      "epoch": 0.26739783261522393,
      "grad_norm": 0.00023158651310950518,
      "learning_rate": 1.5425957690108635e-05,
      "loss": 0.0016,
      "step": 6400
    },
    {
      "epoch": 0.26948687818253036,
      "grad_norm": 1.8129172474345978e-07,
      "learning_rate": 1.5381976514051987e-05,
      "loss": 0.0009,
      "step": 6450
    },
    {
      "epoch": 0.2715759237498368,
      "grad_norm": 0.006175845395773649,
      "learning_rate": 1.533799533799534e-05,
      "loss": 0.0003,
      "step": 6500
    },
    {
      "epoch": 0.27366496931714324,
      "grad_norm": 1.5551815522485413e-05,
      "learning_rate": 1.529401416193869e-05,
      "loss": 0.0008,
      "step": 6550
    },
    {
      "epoch": 0.27575401488444967,
      "grad_norm": 0.0040847365744411945,
      "learning_rate": 1.5250032985882044e-05,
      "loss": 0.0031,
      "step": 6600
    },
    {
      "epoch": 0.2778430604517561,
      "grad_norm": 0.00014401256339624524,
      "learning_rate": 1.5206051809825395e-05,
      "loss": 0.0004,
      "step": 6650
    },
    {
      "epoch": 0.27993210601906254,
      "grad_norm": 2.979045120810042e-06,
      "learning_rate": 1.5162070633768748e-05,
      "loss": 0.002,
      "step": 6700
    },
    {
      "epoch": 0.282021151586369,
      "grad_norm": 0.009707442484796047,
      "learning_rate": 1.51180894577121e-05,
      "loss": 0.0002,
      "step": 6750
    },
    {
      "epoch": 0.2841101971536754,
      "grad_norm": 4.56068228231743e-05,
      "learning_rate": 1.5074108281655454e-05,
      "loss": 0.0001,
      "step": 6800
    },
    {
      "epoch": 0.28619924272098185,
      "grad_norm": 0.1386854201555252,
      "learning_rate": 1.5030127105598804e-05,
      "loss": 0.0032,
      "step": 6850
    },
    {
      "epoch": 0.2882882882882883,
      "grad_norm": 1.3836306607117876e-06,
      "learning_rate": 1.4986145929542157e-05,
      "loss": 0.0012,
      "step": 6900
    },
    {
      "epoch": 0.2903773338555947,
      "grad_norm": 2.74193735094741e-06,
      "learning_rate": 1.494216475348551e-05,
      "loss": 0.002,
      "step": 6950
    },
    {
      "epoch": 0.29246637942290116,
      "grad_norm": 4.380139671411598e-06,
      "learning_rate": 1.4898183577428861e-05,
      "loss": 0.0064,
      "step": 7000
    },
    {
      "epoch": 0.2945554249902076,
      "grad_norm": 0.00033243681536987424,
      "learning_rate": 1.4854202401372213e-05,
      "loss": 0.0037,
      "step": 7050
    },
    {
      "epoch": 0.29664447055751403,
      "grad_norm": 3.0060164135647938e-05,
      "learning_rate": 1.4810221225315567e-05,
      "loss": 0.005,
      "step": 7100
    },
    {
      "epoch": 0.29873351612482046,
      "grad_norm": 0.005402497947216034,
      "learning_rate": 1.4766240049258917e-05,
      "loss": 0.0036,
      "step": 7150
    },
    {
      "epoch": 0.3008225616921269,
      "grad_norm": 3.933950665668817e-06,
      "learning_rate": 1.472225887320227e-05,
      "loss": 0.0016,
      "step": 7200
    },
    {
      "epoch": 0.30291160725943334,
      "grad_norm": 0.04320033639669418,
      "learning_rate": 1.4678277697145622e-05,
      "loss": 0.0025,
      "step": 7250
    },
    {
      "epoch": 0.30500065282673977,
      "grad_norm": 0.0027699521742761135,
      "learning_rate": 1.4634296521088976e-05,
      "loss": 0.0057,
      "step": 7300
    },
    {
      "epoch": 0.3070896983940462,
      "grad_norm": 6.876082807139028e-06,
      "learning_rate": 1.4590315345032326e-05,
      "loss": 0.0007,
      "step": 7350
    },
    {
      "epoch": 0.30917874396135264,
      "grad_norm": 3.578109271984431e-06,
      "learning_rate": 1.454633416897568e-05,
      "loss": 0.0001,
      "step": 7400
    },
    {
      "epoch": 0.3112677895286591,
      "grad_norm": 1.9699691620189697e-05,
      "learning_rate": 1.4502352992919032e-05,
      "loss": 0.004,
      "step": 7450
    },
    {
      "epoch": 0.3133568350959655,
      "grad_norm": 4.671760507335421e-06,
      "learning_rate": 1.4458371816862385e-05,
      "loss": 0.0028,
      "step": 7500
    },
    {
      "epoch": 0.31544588066327195,
      "grad_norm": 0.19393602013587952,
      "learning_rate": 1.4414390640805735e-05,
      "loss": 0.0014,
      "step": 7550
    },
    {
      "epoch": 0.3175349262305784,
      "grad_norm": 5.225851964496542e-06,
      "learning_rate": 1.4370409464749089e-05,
      "loss": 0.0013,
      "step": 7600
    },
    {
      "epoch": 0.3196239717978848,
      "grad_norm": 0.0001935763721121475,
      "learning_rate": 1.4326428288692439e-05,
      "loss": 0.0086,
      "step": 7650
    },
    {
      "epoch": 0.32171301736519126,
      "grad_norm": 0.12031472474336624,
      "learning_rate": 1.4282447112635793e-05,
      "loss": 0.0012,
      "step": 7700
    },
    {
      "epoch": 0.3238020629324977,
      "grad_norm": 1.757668906066101e-05,
      "learning_rate": 1.4238465936579145e-05,
      "loss": 0.0015,
      "step": 7750
    },
    {
      "epoch": 0.3258911084998041,
      "grad_norm": 3.5758246667683125e-05,
      "learning_rate": 1.4194484760522498e-05,
      "loss": 0.0001,
      "step": 7800
    },
    {
      "epoch": 0.32798015406711056,
      "grad_norm": 0.6681075096130371,
      "learning_rate": 1.4150503584465848e-05,
      "loss": 0.0066,
      "step": 7850
    },
    {
      "epoch": 0.330069199634417,
      "grad_norm": 0.00022736284881830215,
      "learning_rate": 1.4106522408409202e-05,
      "loss": 0.0027,
      "step": 7900
    },
    {
      "epoch": 0.3321582452017235,
      "grad_norm": 2.9070162099742447e-07,
      "learning_rate": 1.4062541232352554e-05,
      "loss": 0.0022,
      "step": 7950
    },
    {
      "epoch": 0.3342472907690299,
      "grad_norm": 0.025122899562120438,
      "learning_rate": 1.4018560056295907e-05,
      "loss": 0.0051,
      "step": 8000
    },
    {
      "epoch": 0.33633633633633636,
      "grad_norm": 0.0007775981212034822,
      "learning_rate": 1.3974578880239258e-05,
      "loss": 0.0038,
      "step": 8050
    },
    {
      "epoch": 0.3384253819036428,
      "grad_norm": 1.1935588190681301e-05,
      "learning_rate": 1.3930597704182611e-05,
      "loss": 0.0008,
      "step": 8100
    },
    {
      "epoch": 0.34051442747094923,
      "grad_norm": 0.0008237727452069521,
      "learning_rate": 1.3887496151647095e-05,
      "loss": 0.0043,
      "step": 8150
    },
    {
      "epoch": 0.34260347303825567,
      "grad_norm": 0.003772015916183591,
      "learning_rate": 1.3843514975590448e-05,
      "loss": 0.0004,
      "step": 8200
    },
    {
      "epoch": 0.3446925186055621,
      "grad_norm": 1.9789706584560918e-06,
      "learning_rate": 1.37995337995338e-05,
      "loss": 0.0011,
      "step": 8250
    },
    {
      "epoch": 0.34678156417286854,
      "grad_norm": 0.00026237862766720355,
      "learning_rate": 1.3755552623477154e-05,
      "loss": 0.0019,
      "step": 8300
    },
    {
      "epoch": 0.348870609740175,
      "grad_norm": 7.118036592146382e-06,
      "learning_rate": 1.3711571447420504e-05,
      "loss": 0.0026,
      "step": 8350
    },
    {
      "epoch": 0.3509596553074814,
      "grad_norm": 1.7371783656017215e-07,
      "learning_rate": 1.3667590271363858e-05,
      "loss": 0.0002,
      "step": 8400
    },
    {
      "epoch": 0.35304870087478785,
      "grad_norm": 0.05932826176285744,
      "learning_rate": 1.362360909530721e-05,
      "loss": 0.004,
      "step": 8450
    },
    {
      "epoch": 0.3551377464420943,
      "grad_norm": 1.352184517600108e-05,
      "learning_rate": 1.3579627919250561e-05,
      "loss": 0.007,
      "step": 8500
    },
    {
      "epoch": 0.3572267920094007,
      "grad_norm": 3.7834195154573536e-06,
      "learning_rate": 1.3535646743193913e-05,
      "loss": 0.0045,
      "step": 8550
    },
    {
      "epoch": 0.35931583757670715,
      "grad_norm": 0.0003366436285432428,
      "learning_rate": 1.3491665567137267e-05,
      "loss": 0.0046,
      "step": 8600
    },
    {
      "epoch": 0.3614048831440136,
      "grad_norm": 1.2598711691680364e-05,
      "learning_rate": 1.3447684391080617e-05,
      "loss": 0.0007,
      "step": 8650
    },
    {
      "epoch": 0.36349392871132,
      "grad_norm": 0.0002880646497942507,
      "learning_rate": 1.340370321502397e-05,
      "loss": 0.0013,
      "step": 8700
    },
    {
      "epoch": 0.36558297427862646,
      "grad_norm": 1.5895506294327788e-05,
      "learning_rate": 1.3359722038967323e-05,
      "loss": 0.0032,
      "step": 8750
    },
    {
      "epoch": 0.3676720198459329,
      "grad_norm": 0.0009835163364186883,
      "learning_rate": 1.3315740862910676e-05,
      "loss": 0.0041,
      "step": 8800
    },
    {
      "epoch": 0.36976106541323933,
      "grad_norm": 0.00024952273815870285,
      "learning_rate": 1.3271759686854026e-05,
      "loss": 0.0003,
      "step": 8850
    },
    {
      "epoch": 0.37185011098054577,
      "grad_norm": 0.00020481178944464773,
      "learning_rate": 1.322777851079738e-05,
      "loss": 0.0012,
      "step": 8900
    },
    {
      "epoch": 0.3739391565478522,
      "grad_norm": 5.248180605121888e-05,
      "learning_rate": 1.3183797334740732e-05,
      "loss": 0.0014,
      "step": 8950
    },
    {
      "epoch": 0.37602820211515864,
      "grad_norm": 5.119586603541393e-06,
      "learning_rate": 1.3139816158684084e-05,
      "loss": 0.0026,
      "step": 9000
    },
    {
      "epoch": 0.3781172476824651,
      "grad_norm": 0.0001276065013371408,
      "learning_rate": 1.3095834982627436e-05,
      "loss": 0.0071,
      "step": 9050
    },
    {
      "epoch": 0.3802062932497715,
      "grad_norm": 1.171235453512054e-05,
      "learning_rate": 1.3051853806570789e-05,
      "loss": 0.005,
      "step": 9100
    },
    {
      "epoch": 0.38229533881707795,
      "grad_norm": 0.0005064727156423032,
      "learning_rate": 1.300787263051414e-05,
      "loss": 0.0004,
      "step": 9150
    },
    {
      "epoch": 0.3843843843843844,
      "grad_norm": 6.307284365902888e-06,
      "learning_rate": 1.2963891454457493e-05,
      "loss": 0.001,
      "step": 9200
    },
    {
      "epoch": 0.3864734299516908,
      "grad_norm": 4.5771506847813725e-05,
      "learning_rate": 1.2919910278400845e-05,
      "loss": 0.0042,
      "step": 9250
    },
    {
      "epoch": 0.38856247551899725,
      "grad_norm": 9.385299199493602e-05,
      "learning_rate": 1.2875929102344198e-05,
      "loss": 0.0013,
      "step": 9300
    },
    {
      "epoch": 0.3906515210863037,
      "grad_norm": 4.278456253814511e-05,
      "learning_rate": 1.2831947926287549e-05,
      "loss": 0.0012,
      "step": 9350
    },
    {
      "epoch": 0.3927405666536101,
      "grad_norm": 5.921205593040213e-05,
      "learning_rate": 1.2787966750230902e-05,
      "loss": 0.0039,
      "step": 9400
    },
    {
      "epoch": 0.39482961222091656,
      "grad_norm": 8.032675395952538e-07,
      "learning_rate": 1.2743985574174254e-05,
      "loss": 0.0013,
      "step": 9450
    },
    {
      "epoch": 0.396918657788223,
      "grad_norm": 6.392978320945986e-06,
      "learning_rate": 1.2700004398117608e-05,
      "loss": 0.0005,
      "step": 9500
    },
    {
      "epoch": 0.39900770335552943,
      "grad_norm": 0.00014957203529775143,
      "learning_rate": 1.2656023222060958e-05,
      "loss": 0.0038,
      "step": 9550
    },
    {
      "epoch": 0.40109674892283587,
      "grad_norm": 4.3659110815497115e-06,
      "learning_rate": 1.2612042046004311e-05,
      "loss": 0.0037,
      "step": 9600
    },
    {
      "epoch": 0.4031857944901423,
      "grad_norm": 0.0021320830564945936,
      "learning_rate": 1.2568060869947663e-05,
      "loss": 0.0015,
      "step": 9650
    },
    {
      "epoch": 0.40527484005744874,
      "grad_norm": 1.799900201149285e-05,
      "learning_rate": 1.2524079693891015e-05,
      "loss": 0.005,
      "step": 9700
    },
    {
      "epoch": 0.4073638856247552,
      "grad_norm": 0.0005001046811230481,
      "learning_rate": 1.2480098517834367e-05,
      "loss": 0.0009,
      "step": 9750
    },
    {
      "epoch": 0.4094529311920616,
      "grad_norm": 1.0897560059675016e-05,
      "learning_rate": 1.243611734177772e-05,
      "loss": 0.0002,
      "step": 9800
    },
    {
      "epoch": 0.41154197675936804,
      "grad_norm": 3.2955429105641088e-06,
      "learning_rate": 1.239213616572107e-05,
      "loss": 0.0005,
      "step": 9850
    },
    {
      "epoch": 0.4136310223266745,
      "grad_norm": 0.0014082459965720773,
      "learning_rate": 1.2348154989664424e-05,
      "loss": 0.0094,
      "step": 9900
    },
    {
      "epoch": 0.4157200678939809,
      "grad_norm": 0.07341238856315613,
      "learning_rate": 1.2304173813607776e-05,
      "loss": 0.0049,
      "step": 9950
    },
    {
      "epoch": 0.41780911346128735,
      "grad_norm": 8.331974640896078e-06,
      "learning_rate": 1.226019263755113e-05,
      "loss": 0.0023,
      "step": 10000
    },
    {
      "epoch": 0.4198981590285938,
      "grad_norm": 0.00036088062915951014,
      "learning_rate": 1.221621146149448e-05,
      "loss": 0.0007,
      "step": 10050
    },
    {
      "epoch": 0.4219872045959002,
      "grad_norm": 0.08035647124052048,
      "learning_rate": 1.2172230285437834e-05,
      "loss": 0.0024,
      "step": 10100
    },
    {
      "epoch": 0.42407625016320666,
      "grad_norm": 0.0002616621204651892,
      "learning_rate": 1.2128249109381186e-05,
      "loss": 0.0053,
      "step": 10150
    },
    {
      "epoch": 0.42616529573051315,
      "grad_norm": 0.0023530516773462296,
      "learning_rate": 1.2084267933324539e-05,
      "loss": 0.0024,
      "step": 10200
    },
    {
      "epoch": 0.4282543412978196,
      "grad_norm": 0.0010609379969537258,
      "learning_rate": 1.204028675726789e-05,
      "loss": 0.0048,
      "step": 10250
    },
    {
      "epoch": 0.430343386865126,
      "grad_norm": 0.00014219965669326484,
      "learning_rate": 1.1996305581211243e-05,
      "loss": 0.0016,
      "step": 10300
    },
    {
      "epoch": 0.43243243243243246,
      "grad_norm": 1.1044631004333496,
      "learning_rate": 1.1952324405154595e-05,
      "loss": 0.0039,
      "step": 10350
    },
    {
      "epoch": 0.4345214779997389,
      "grad_norm": 0.00020430973381735384,
      "learning_rate": 1.1908343229097947e-05,
      "loss": 0.0023,
      "step": 10400
    },
    {
      "epoch": 0.4366105235670453,
      "grad_norm": 6.541474431287497e-05,
      "learning_rate": 1.1864362053041299e-05,
      "loss": 0.0045,
      "step": 10450
    },
    {
      "epoch": 0.43869956913435176,
      "grad_norm": 2.7445560135674896e-06,
      "learning_rate": 1.1820380876984652e-05,
      "loss": 0.0016,
      "step": 10500
    },
    {
      "epoch": 0.4407886147016582,
      "grad_norm": 7.941381045384333e-05,
      "learning_rate": 1.1776399700928002e-05,
      "loss": 0.0008,
      "step": 10550
    },
    {
      "epoch": 0.44287766026896463,
      "grad_norm": 9.10091694095172e-06,
      "learning_rate": 1.1732418524871356e-05,
      "loss": 0.0029,
      "step": 10600
    },
    {
      "epoch": 0.44496670583627107,
      "grad_norm": 0.0006353436619974673,
      "learning_rate": 1.1688437348814708e-05,
      "loss": 0.004,
      "step": 10650
    },
    {
      "epoch": 0.4470557514035775,
      "grad_norm": 3.114033825113438e-05,
      "learning_rate": 1.1644456172758061e-05,
      "loss": 0.0013,
      "step": 10700
    },
    {
      "epoch": 0.44914479697088394,
      "grad_norm": 0.0002597162965685129,
      "learning_rate": 1.1600474996701412e-05,
      "loss": 0.0005,
      "step": 10750
    },
    {
      "epoch": 0.4512338425381904,
      "grad_norm": 3.0039160265005194e-05,
      "learning_rate": 1.1556493820644765e-05,
      "loss": 0.0033,
      "step": 10800
    },
    {
      "epoch": 0.4533228881054968,
      "grad_norm": 9.258091449737549e-05,
      "learning_rate": 1.1512512644588117e-05,
      "loss": 0.0012,
      "step": 10850
    },
    {
      "epoch": 0.45541193367280325,
      "grad_norm": 6.077415036997991e-06,
      "learning_rate": 1.1468531468531469e-05,
      "loss": 0.0003,
      "step": 10900
    },
    {
      "epoch": 0.4575009792401097,
      "grad_norm": 1.9380036974325776e-05,
      "learning_rate": 1.142455029247482e-05,
      "loss": 0.0008,
      "step": 10950
    },
    {
      "epoch": 0.4595900248074161,
      "grad_norm": 0.0009684653487056494,
      "learning_rate": 1.1380569116418174e-05,
      "loss": 0.0026,
      "step": 11000
    },
    {
      "epoch": 0.46167907037472256,
      "grad_norm": 1.411657706285041e-07,
      "learning_rate": 1.1336587940361525e-05,
      "loss": 0.0019,
      "step": 11050
    },
    {
      "epoch": 0.463768115942029,
      "grad_norm": 1.5338526964114862e-06,
      "learning_rate": 1.1292606764304878e-05,
      "loss": 0.0005,
      "step": 11100
    },
    {
      "epoch": 0.4658571615093354,
      "grad_norm": 9.06768582353834e-06,
      "learning_rate": 1.124862558824823e-05,
      "loss": 0.0004,
      "step": 11150
    },
    {
      "epoch": 0.46794620707664186,
      "grad_norm": 2.775038592517376e-05,
      "learning_rate": 1.1204644412191584e-05,
      "loss": 0.0001,
      "step": 11200
    },
    {
      "epoch": 0.4700352526439483,
      "grad_norm": 8.7631542555755e-06,
      "learning_rate": 1.1160663236134934e-05,
      "loss": 0.0003,
      "step": 11250
    },
    {
      "epoch": 0.47212429821125473,
      "grad_norm": 1.5376056694549334e-07,
      "learning_rate": 1.1116682060078287e-05,
      "loss": 0.0039,
      "step": 11300
    },
    {
      "epoch": 0.47421334377856117,
      "grad_norm": 3.240135993110016e-05,
      "learning_rate": 1.107270088402164e-05,
      "loss": 0.0033,
      "step": 11350
    },
    {
      "epoch": 0.4763023893458676,
      "grad_norm": 0.00019835916464217007,
      "learning_rate": 1.1028719707964993e-05,
      "loss": 0.0034,
      "step": 11400
    },
    {
      "epoch": 0.47839143491317404,
      "grad_norm": 0.004036541096866131,
      "learning_rate": 1.0984738531908343e-05,
      "loss": 0.0008,
      "step": 11450
    },
    {
      "epoch": 0.4804804804804805,
      "grad_norm": 0.0014096376253291965,
      "learning_rate": 1.0940757355851697e-05,
      "loss": 0.0037,
      "step": 11500
    },
    {
      "epoch": 0.4825695260477869,
      "grad_norm": 8.029698506106797e-07,
      "learning_rate": 1.0896776179795049e-05,
      "loss": 0.0068,
      "step": 11550
    },
    {
      "epoch": 0.48465857161509335,
      "grad_norm": 5.37137611900107e-06,
      "learning_rate": 1.08527950037384e-05,
      "loss": 0.0014,
      "step": 11600
    },
    {
      "epoch": 0.4867476171823998,
      "grad_norm": 0.0005473301862366498,
      "learning_rate": 1.0808813827681752e-05,
      "loss": 0.0035,
      "step": 11650
    },
    {
      "epoch": 0.4888366627497062,
      "grad_norm": 6.966742148506455e-06,
      "learning_rate": 1.0764832651625106e-05,
      "loss": 0.0062,
      "step": 11700
    },
    {
      "epoch": 0.49092570831701265,
      "grad_norm": 0.0656626895070076,
      "learning_rate": 1.0720851475568456e-05,
      "loss": 0.0015,
      "step": 11750
    },
    {
      "epoch": 0.4930147538843191,
      "grad_norm": 0.0019320202991366386,
      "learning_rate": 1.067687029951181e-05,
      "loss": 0.0005,
      "step": 11800
    },
    {
      "epoch": 0.4951037994516255,
      "grad_norm": 4.2830822621908737e-07,
      "learning_rate": 1.0632889123455162e-05,
      "loss": 0.0008,
      "step": 11850
    },
    {
      "epoch": 0.49719284501893196,
      "grad_norm": 0.0001269374042749405,
      "learning_rate": 1.0588907947398515e-05,
      "loss": 0.0049,
      "step": 11900
    },
    {
      "epoch": 0.4992818905862384,
      "grad_norm": 2.651082832016982e-05,
      "learning_rate": 1.0544926771341865e-05,
      "loss": 0.0016,
      "step": 11950
    },
    {
      "epoch": 0.5013709361535449,
      "grad_norm": 4.464466485387675e-07,
      "learning_rate": 1.0500945595285219e-05,
      "loss": 0.0023,
      "step": 12000
    },
    {
      "epoch": 0.5034599817208513,
      "grad_norm": 0.000578728155232966,
      "learning_rate": 1.045696441922857e-05,
      "loss": 0.0009,
      "step": 12050
    },
    {
      "epoch": 0.5055490272881578,
      "grad_norm": 0.004397651646286249,
      "learning_rate": 1.0412983243171924e-05,
      "loss": 0.0002,
      "step": 12100
    },
    {
      "epoch": 0.5076380728554641,
      "grad_norm": 1.541054189146962e-05,
      "learning_rate": 1.0369002067115275e-05,
      "loss": 0.0001,
      "step": 12150
    },
    {
      "epoch": 0.5097271184227706,
      "grad_norm": 0.0094932084903121,
      "learning_rate": 1.0325020891058628e-05,
      "loss": 0.0005,
      "step": 12200
    },
    {
      "epoch": 0.511816163990077,
      "grad_norm": 2.0380223304528045e-06,
      "learning_rate": 1.0281039715001978e-05,
      "loss": 0.0028,
      "step": 12250
    },
    {
      "epoch": 0.5139052095573835,
      "grad_norm": 2.7992797186016105e-05,
      "learning_rate": 1.0237058538945332e-05,
      "loss": 0.0031,
      "step": 12300
    },
    {
      "epoch": 0.5159942551246899,
      "grad_norm": 0.00018460664432495832,
      "learning_rate": 1.0193077362888684e-05,
      "loss": 0.0102,
      "step": 12350
    },
    {
      "epoch": 0.5180833006919964,
      "grad_norm": 1.2285284356039483e-05,
      "learning_rate": 1.0149096186832037e-05,
      "loss": 0.0003,
      "step": 12400
    },
    {
      "epoch": 0.5201723462593028,
      "grad_norm": 0.004925815388560295,
      "learning_rate": 1.0105115010775388e-05,
      "loss": 0.0001,
      "step": 12450
    },
    {
      "epoch": 0.5222613918266092,
      "grad_norm": 5.326069185684901e-07,
      "learning_rate": 1.0061133834718741e-05,
      "loss": 0.0001,
      "step": 12500
    },
    {
      "epoch": 0.5243504373939156,
      "grad_norm": 2.210483762610238e-05,
      "learning_rate": 1.0018032282183225e-05,
      "loss": 0.0055,
      "step": 12550
    },
    {
      "epoch": 0.5264394829612221,
      "grad_norm": 9.927771316142753e-07,
      "learning_rate": 9.974051106126578e-06,
      "loss": 0.0001,
      "step": 12600
    },
    {
      "epoch": 0.5285285285285285,
      "grad_norm": 0.002566932002082467,
      "learning_rate": 9.93006993006993e-06,
      "loss": 0.0114,
      "step": 12650
    },
    {
      "epoch": 0.530617574095835,
      "grad_norm": 1.5735301985841943e-06,
      "learning_rate": 9.886088754013284e-06,
      "loss": 0.0009,
      "step": 12700
    },
    {
      "epoch": 0.5327066196631414,
      "grad_norm": 0.06869620084762573,
      "learning_rate": 9.842107577956636e-06,
      "loss": 0.0059,
      "step": 12750
    },
    {
      "epoch": 0.5347956652304479,
      "grad_norm": 0.00012789148604497313,
      "learning_rate": 9.798126401899988e-06,
      "loss": 0.0011,
      "step": 12800
    },
    {
      "epoch": 0.5368847107977542,
      "grad_norm": 0.008789257146418095,
      "learning_rate": 9.75414522584334e-06,
      "loss": 0.0023,
      "step": 12850
    },
    {
      "epoch": 0.5389737563650607,
      "grad_norm": 2.0631352526834235e-05,
      "learning_rate": 9.710164049786693e-06,
      "loss": 0.0024,
      "step": 12900
    },
    {
      "epoch": 0.5410628019323671,
      "grad_norm": 3.1064158179106016e-07,
      "learning_rate": 9.666182873730045e-06,
      "loss": 0.0011,
      "step": 12950
    },
    {
      "epoch": 0.5431518474996736,
      "grad_norm": 4.518814193943399e-07,
      "learning_rate": 9.622201697673397e-06,
      "loss": 0.0001,
      "step": 13000
    },
    {
      "epoch": 0.54524089306698,
      "grad_norm": 0.0009981532348319888,
      "learning_rate": 9.578220521616749e-06,
      "loss": 0.002,
      "step": 13050
    },
    {
      "epoch": 0.5473299386342865,
      "grad_norm": 0.0373673290014267,
      "learning_rate": 9.5342393455601e-06,
      "loss": 0.0003,
      "step": 13100
    },
    {
      "epoch": 0.5494189842015929,
      "grad_norm": 2.5501885829726234e-06,
      "learning_rate": 9.490258169503454e-06,
      "loss": 0.006,
      "step": 13150
    },
    {
      "epoch": 0.5515080297688993,
      "grad_norm": 2.1751754957222147e-06,
      "learning_rate": 9.446276993446806e-06,
      "loss": 0.0033,
      "step": 13200
    },
    {
      "epoch": 0.5535970753362057,
      "grad_norm": 0.1432565450668335,
      "learning_rate": 9.402295817390158e-06,
      "loss": 0.0013,
      "step": 13250
    },
    {
      "epoch": 0.5556861209035122,
      "grad_norm": 1.739390569355237e-07,
      "learning_rate": 9.35831464133351e-06,
      "loss": 0.0007,
      "step": 13300
    },
    {
      "epoch": 0.5577751664708186,
      "grad_norm": 0.0017843005480244756,
      "learning_rate": 9.314333465276862e-06,
      "loss": 0.0062,
      "step": 13350
    },
    {
      "epoch": 0.5598642120381251,
      "grad_norm": 0.21151398122310638,
      "learning_rate": 9.270352289220215e-06,
      "loss": 0.0039,
      "step": 13400
    },
    {
      "epoch": 0.5619532576054315,
      "grad_norm": 4.378739049570868e-06,
      "learning_rate": 9.226371113163567e-06,
      "loss": 0.0034,
      "step": 13450
    },
    {
      "epoch": 0.564042303172738,
      "grad_norm": 3.375344704181771e-06,
      "learning_rate": 9.182389937106919e-06,
      "loss": 0.0029,
      "step": 13500
    },
    {
      "epoch": 0.5661313487400443,
      "grad_norm": 0.0001648439938435331,
      "learning_rate": 9.138408761050271e-06,
      "loss": 0.0002,
      "step": 13550
    },
    {
      "epoch": 0.5682203943073508,
      "grad_norm": 0.1340412199497223,
      "learning_rate": 9.094427584993623e-06,
      "loss": 0.0017,
      "step": 13600
    },
    {
      "epoch": 0.5703094398746573,
      "grad_norm": 2.106788451783359e-05,
      "learning_rate": 9.050446408936976e-06,
      "loss": 0.001,
      "step": 13650
    },
    {
      "epoch": 0.5723984854419637,
      "grad_norm": 3.074438552630454e-07,
      "learning_rate": 9.006465232880328e-06,
      "loss": 0.0003,
      "step": 13700
    },
    {
      "epoch": 0.5744875310092702,
      "grad_norm": 7.418610039167106e-06,
      "learning_rate": 8.96248405682368e-06,
      "loss": 0.009,
      "step": 13750
    },
    {
      "epoch": 0.5765765765765766,
      "grad_norm": 6.492419925052673e-05,
      "learning_rate": 8.918502880767032e-06,
      "loss": 0.0007,
      "step": 13800
    },
    {
      "epoch": 0.5786656221438831,
      "grad_norm": 0.006250247359275818,
      "learning_rate": 8.874521704710386e-06,
      "loss": 0.0019,
      "step": 13850
    },
    {
      "epoch": 0.5807546677111894,
      "grad_norm": 0.7432616353034973,
      "learning_rate": 8.830540528653738e-06,
      "loss": 0.0041,
      "step": 13900
    },
    {
      "epoch": 0.5828437132784959,
      "grad_norm": 9.097760994336568e-06,
      "learning_rate": 8.78655935259709e-06,
      "loss": 0.0018,
      "step": 13950
    },
    {
      "epoch": 0.5849327588458023,
      "grad_norm": 1.7762027937351377e-06,
      "learning_rate": 8.742578176540441e-06,
      "loss": 0.0034,
      "step": 14000
    },
    {
      "epoch": 0.5870218044131088,
      "grad_norm": 0.010475887916982174,
      "learning_rate": 8.698597000483793e-06,
      "loss": 0.0026,
      "step": 14050
    },
    {
      "epoch": 0.5891108499804152,
      "grad_norm": 1.842681558628101e-05,
      "learning_rate": 8.654615824427147e-06,
      "loss": 0.0026,
      "step": 14100
    },
    {
      "epoch": 0.5911998955477217,
      "grad_norm": 5.855121344211511e-05,
      "learning_rate": 8.610634648370499e-06,
      "loss": 0.002,
      "step": 14150
    },
    {
      "epoch": 0.5932889411150281,
      "grad_norm": 0.011006234213709831,
      "learning_rate": 8.56665347231385e-06,
      "loss": 0.0005,
      "step": 14200
    },
    {
      "epoch": 0.5953779866823345,
      "grad_norm": 3.4169278251283686e-07,
      "learning_rate": 8.522672296257202e-06,
      "loss": 0.0021,
      "step": 14250
    },
    {
      "epoch": 0.5974670322496409,
      "grad_norm": 2.355677452214877e-06,
      "learning_rate": 8.478691120200554e-06,
      "loss": 0.0013,
      "step": 14300
    },
    {
      "epoch": 0.5995560778169474,
      "grad_norm": 0.00013724021846428514,
      "learning_rate": 8.434709944143908e-06,
      "loss": 0.0017,
      "step": 14350
    },
    {
      "epoch": 0.6016451233842538,
      "grad_norm": 0.0002477554080542177,
      "learning_rate": 8.39072876808726e-06,
      "loss": 0.0003,
      "step": 14400
    },
    {
      "epoch": 0.6037341689515603,
      "grad_norm": 0.0032081464305520058,
      "learning_rate": 8.346747592030612e-06,
      "loss": 0.0009,
      "step": 14450
    },
    {
      "epoch": 0.6058232145188667,
      "grad_norm": 2.72012243840436e-06,
      "learning_rate": 8.302766415973964e-06,
      "loss": 0.0021,
      "step": 14500
    },
    {
      "epoch": 0.6079122600861732,
      "grad_norm": 7.005551196925808e-07,
      "learning_rate": 8.258785239917315e-06,
      "loss": 0.0058,
      "step": 14550
    },
    {
      "epoch": 0.6100013056534795,
      "grad_norm": 1.1193794762220932e-06,
      "learning_rate": 8.214804063860669e-06,
      "loss": 0.0033,
      "step": 14600
    },
    {
      "epoch": 0.612090351220786,
      "grad_norm": 2.5789113351493143e-06,
      "learning_rate": 8.170822887804021e-06,
      "loss": 0.0019,
      "step": 14650
    },
    {
      "epoch": 0.6141793967880924,
      "grad_norm": 3.061707730012131e-06,
      "learning_rate": 8.126841711747373e-06,
      "loss": 0.0001,
      "step": 14700
    },
    {
      "epoch": 0.6162684423553989,
      "grad_norm": 1.8774575437419116e-05,
      "learning_rate": 8.082860535690725e-06,
      "loss": 0.006,
      "step": 14750
    },
    {
      "epoch": 0.6183574879227053,
      "grad_norm": 1.18045181807247e-06,
      "learning_rate": 8.038879359634078e-06,
      "loss": 0.0004,
      "step": 14800
    },
    {
      "epoch": 0.6204465334900118,
      "grad_norm": 0.002370506292209029,
      "learning_rate": 7.99489818357743e-06,
      "loss": 0.0009,
      "step": 14850
    },
    {
      "epoch": 0.6225355790573182,
      "grad_norm": 0.00045081262942403555,
      "learning_rate": 7.950917007520782e-06,
      "loss": 0.0009,
      "step": 14900
    },
    {
      "epoch": 0.6246246246246246,
      "grad_norm": 6.335282523650676e-05,
      "learning_rate": 7.906935831464134e-06,
      "loss": 0.001,
      "step": 14950
    },
    {
      "epoch": 0.626713670191931,
      "grad_norm": 0.0005319746560417116,
      "learning_rate": 7.862954655407486e-06,
      "loss": 0.0115,
      "step": 15000
    },
    {
      "epoch": 0.6288027157592375,
      "grad_norm": 2.240967114630621e-05,
      "learning_rate": 7.81897347935084e-06,
      "loss": 0.0023,
      "step": 15050
    },
    {
      "epoch": 0.6308917613265439,
      "grad_norm": 1.1070164873672184e-05,
      "learning_rate": 7.774992303294191e-06,
      "loss": 0.0039,
      "step": 15100
    },
    {
      "epoch": 0.6329808068938504,
      "grad_norm": 0.00017021872918121517,
      "learning_rate": 7.731011127237543e-06,
      "loss": 0.004,
      "step": 15150
    },
    {
      "epoch": 0.6350698524611568,
      "grad_norm": 3.5351516999071464e-05,
      "learning_rate": 7.687029951180895e-06,
      "loss": 0.0054,
      "step": 15200
    },
    {
      "epoch": 0.6371588980284633,
      "grad_norm": 4.2020117689389735e-05,
      "learning_rate": 7.643048775124247e-06,
      "loss": 0.0013,
      "step": 15250
    },
    {
      "epoch": 0.6392479435957696,
      "grad_norm": 0.00038460982614196837,
      "learning_rate": 7.5990675990676e-06,
      "loss": 0.001,
      "step": 15300
    },
    {
      "epoch": 0.6413369891630761,
      "grad_norm": 0.002747158519923687,
      "learning_rate": 7.5550864230109524e-06,
      "loss": 0.0011,
      "step": 15350
    },
    {
      "epoch": 0.6434260347303825,
      "grad_norm": 0.012033707462251186,
      "learning_rate": 7.511984870475437e-06,
      "loss": 0.003,
      "step": 15400
    },
    {
      "epoch": 0.645515080297689,
      "grad_norm": 1.463089938624762e-05,
      "learning_rate": 7.4680036944187896e-06,
      "loss": 0.0066,
      "step": 15450
    },
    {
      "epoch": 0.6476041258649954,
      "grad_norm": 9.189593401970342e-05,
      "learning_rate": 7.4240225183621415e-06,
      "loss": 0.0002,
      "step": 15500
    },
    {
      "epoch": 0.6496931714323019,
      "grad_norm": 9.409335325472057e-05,
      "learning_rate": 7.380041342305494e-06,
      "loss": 0.0001,
      "step": 15550
    },
    {
      "epoch": 0.6517822169996083,
      "grad_norm": 0.00019852160767186433,
      "learning_rate": 7.336060166248846e-06,
      "loss": 0.0013,
      "step": 15600
    },
    {
      "epoch": 0.6538712625669147,
      "grad_norm": 6.166887033032253e-05,
      "learning_rate": 7.292078990192199e-06,
      "loss": 0.0002,
      "step": 15650
    },
    {
      "epoch": 0.6559603081342211,
      "grad_norm": 1.3221885637904052e-05,
      "learning_rate": 7.248097814135551e-06,
      "loss": 0.0022,
      "step": 15700
    },
    {
      "epoch": 0.6580493537015276,
      "grad_norm": 0.00010853445564862341,
      "learning_rate": 7.204116638078903e-06,
      "loss": 0.0005,
      "step": 15750
    },
    {
      "epoch": 0.660138399268834,
      "grad_norm": 0.004120909608900547,
      "learning_rate": 7.160135462022255e-06,
      "loss": 0.0021,
      "step": 15800
    },
    {
      "epoch": 0.6622274448361405,
      "grad_norm": 0.000435197347542271,
      "learning_rate": 7.116154285965607e-06,
      "loss": 0.0004,
      "step": 15850
    },
    {
      "epoch": 0.664316490403447,
      "grad_norm": 6.31142538622953e-05,
      "learning_rate": 7.07217310990896e-06,
      "loss": 0.0001,
      "step": 15900
    },
    {
      "epoch": 0.6664055359707534,
      "grad_norm": 0.00012309876910876483,
      "learning_rate": 7.028191933852312e-06,
      "loss": 0.0028,
      "step": 15950
    },
    {
      "epoch": 0.6684945815380599,
      "grad_norm": 4.551061465463135e-06,
      "learning_rate": 6.9842107577956646e-06,
      "loss": 0.0004,
      "step": 16000
    },
    {
      "epoch": 0.6705836271053662,
      "grad_norm": 0.00019728763436432928,
      "learning_rate": 6.9402295817390165e-06,
      "loss": 0.001,
      "step": 16050
    },
    {
      "epoch": 0.6726726726726727,
      "grad_norm": 2.3267334370302706e-07,
      "learning_rate": 6.896248405682368e-06,
      "loss": 0.002,
      "step": 16100
    },
    {
      "epoch": 0.6747617182399791,
      "grad_norm": 0.0012721240054816008,
      "learning_rate": 6.852267229625721e-06,
      "loss": 0.0012,
      "step": 16150
    },
    {
      "epoch": 0.6768507638072856,
      "grad_norm": 0.08870311081409454,
      "learning_rate": 6.808286053569073e-06,
      "loss": 0.0039,
      "step": 16200
    },
    {
      "epoch": 0.678939809374592,
      "grad_norm": 2.3057267753756605e-05,
      "learning_rate": 6.764304877512426e-06,
      "loss": 0.0055,
      "step": 16250
    },
    {
      "epoch": 0.6810288549418985,
      "grad_norm": 4.997637461201521e-06,
      "learning_rate": 6.720323701455778e-06,
      "loss": 0.0036,
      "step": 16300
    },
    {
      "epoch": 0.6831179005092048,
      "grad_norm": 0.0004937035264447331,
      "learning_rate": 6.6763425253991295e-06,
      "loss": 0.0005,
      "step": 16350
    },
    {
      "epoch": 0.6852069460765113,
      "grad_norm": 4.077769972354872e-06,
      "learning_rate": 6.632361349342482e-06,
      "loss": 0.0002,
      "step": 16400
    },
    {
      "epoch": 0.6872959916438177,
      "grad_norm": 0.00013574222975876182,
      "learning_rate": 6.588380173285834e-06,
      "loss": 0.0007,
      "step": 16450
    },
    {
      "epoch": 0.6893850372111242,
      "grad_norm": 0.00014668374205939472,
      "learning_rate": 6.544398997229187e-06,
      "loss": 0.0011,
      "step": 16500
    },
    {
      "epoch": 0.6914740827784306,
      "grad_norm": 5.936585694144014e-06,
      "learning_rate": 6.500417821172539e-06,
      "loss": 0.0002,
      "step": 16550
    },
    {
      "epoch": 0.6935631283457371,
      "grad_norm": 0.0032653131056576967,
      "learning_rate": 6.4564366451158914e-06,
      "loss": 0.0047,
      "step": 16600
    },
    {
      "epoch": 0.6956521739130435,
      "grad_norm": 9.74650993157411e-06,
      "learning_rate": 6.412455469059243e-06,
      "loss": 0.0006,
      "step": 16650
    },
    {
      "epoch": 0.69774121948035,
      "grad_norm": 6.9363441070890985e-06,
      "learning_rate": 6.368474293002595e-06,
      "loss": 0.0001,
      "step": 16700
    },
    {
      "epoch": 0.6998302650476563,
      "grad_norm": 6.622648470511194e-06,
      "learning_rate": 6.324493116945948e-06,
      "loss": 0.0006,
      "step": 16750
    },
    {
      "epoch": 0.7019193106149628,
      "grad_norm": 1.063650142896222e-05,
      "learning_rate": 6.2805119408893e-06,
      "loss": 0.0004,
      "step": 16800
    },
    {
      "epoch": 0.7040083561822692,
      "grad_norm": 8.188440574485867e-07,
      "learning_rate": 6.236530764832653e-06,
      "loss": 0.0001,
      "step": 16850
    },
    {
      "epoch": 0.7060974017495757,
      "grad_norm": 7.283177183126099e-06,
      "learning_rate": 6.1925495887760045e-06,
      "loss": 0.003,
      "step": 16900
    },
    {
      "epoch": 0.7081864473168821,
      "grad_norm": 1.6236448573181406e-05,
      "learning_rate": 6.148568412719357e-06,
      "loss": 0.0038,
      "step": 16950
    },
    {
      "epoch": 0.7102754928841886,
      "grad_norm": 0.000386104395147413,
      "learning_rate": 6.104587236662709e-06,
      "loss": 0.0042,
      "step": 17000
    },
    {
      "epoch": 0.7123645384514949,
      "grad_norm": 6.543415565829491e-06,
      "learning_rate": 6.060606060606061e-06,
      "loss": 0.0003,
      "step": 17050
    },
    {
      "epoch": 0.7144535840188014,
      "grad_norm": 6.655715696979314e-05,
      "learning_rate": 6.016624884549414e-06,
      "loss": 0.0005,
      "step": 17100
    },
    {
      "epoch": 0.7165426295861078,
      "grad_norm": 1.257347548744292e-06,
      "learning_rate": 5.972643708492766e-06,
      "loss": 0.0034,
      "step": 17150
    },
    {
      "epoch": 0.7186316751534143,
      "grad_norm": 8.395915642722684e-07,
      "learning_rate": 5.928662532436118e-06,
      "loss": 0.0011,
      "step": 17200
    },
    {
      "epoch": 0.7207207207207207,
      "grad_norm": 1.0435752301418688e-05,
      "learning_rate": 5.88468135637947e-06,
      "loss": 0.003,
      "step": 17250
    },
    {
      "epoch": 0.7228097662880272,
      "grad_norm": 0.002797373803332448,
      "learning_rate": 5.840700180322822e-06,
      "loss": 0.0012,
      "step": 17300
    },
    {
      "epoch": 0.7248988118553336,
      "grad_norm": 0.0011473654303699732,
      "learning_rate": 5.796719004266175e-06,
      "loss": 0.0046,
      "step": 17350
    },
    {
      "epoch": 0.72698785742264,
      "grad_norm": 0.6224279999732971,
      "learning_rate": 5.752737828209527e-06,
      "loss": 0.0026,
      "step": 17400
    },
    {
      "epoch": 0.7290769029899464,
      "grad_norm": 4.6638756430184e-06,
      "learning_rate": 5.7087566521528795e-06,
      "loss": 0.0017,
      "step": 17450
    },
    {
      "epoch": 0.7311659485572529,
      "grad_norm": 0.00022167936549521983,
      "learning_rate": 5.664775476096231e-06,
      "loss": 0.006,
      "step": 17500
    },
    {
      "epoch": 0.7332549941245593,
      "grad_norm": 1.2263400094525423e-05,
      "learning_rate": 5.620794300039584e-06,
      "loss": 0.0014,
      "step": 17550
    },
    {
      "epoch": 0.7353440396918658,
      "grad_norm": 4.190024810668547e-06,
      "learning_rate": 5.576813123982936e-06,
      "loss": 0.0001,
      "step": 17600
    },
    {
      "epoch": 0.7374330852591722,
      "grad_norm": 0.00037472855183295906,
      "learning_rate": 5.532831947926288e-06,
      "loss": 0.0042,
      "step": 17650
    },
    {
      "epoch": 0.7395221308264787,
      "grad_norm": 0.000792289967648685,
      "learning_rate": 5.488850771869641e-06,
      "loss": 0.0001,
      "step": 17700
    },
    {
      "epoch": 0.741611176393785,
      "grad_norm": 3.213916386357596e-07,
      "learning_rate": 5.4448695958129925e-06,
      "loss": 0.0001,
      "step": 17750
    },
    {
      "epoch": 0.7437002219610915,
      "grad_norm": 3.0932358185964404e-07,
      "learning_rate": 5.400888419756345e-06,
      "loss": 0.0001,
      "step": 17800
    },
    {
      "epoch": 0.7457892675283979,
      "grad_norm": 0.0002049870090559125,
      "learning_rate": 5.356907243699697e-06,
      "loss": 0.003,
      "step": 17850
    },
    {
      "epoch": 0.7478783130957044,
      "grad_norm": 9.400197450304404e-05,
      "learning_rate": 5.31292606764305e-06,
      "loss": 0.0009,
      "step": 17900
    },
    {
      "epoch": 0.7499673586630108,
      "grad_norm": 6.341876996884821e-06,
      "learning_rate": 5.268944891586402e-06,
      "loss": 0.0008,
      "step": 17950
    },
    {
      "epoch": 0.7520564042303173,
      "grad_norm": 1.597016307641752e-06,
      "learning_rate": 5.224963715529754e-06,
      "loss": 0.001,
      "step": 18000
    },
    {
      "epoch": 0.7541454497976237,
      "grad_norm": 0.0033418950624763966,
      "learning_rate": 5.180982539473106e-06,
      "loss": 0.0039,
      "step": 18050
    },
    {
      "epoch": 0.7562344953649301,
      "grad_norm": 0.001666566589847207,
      "learning_rate": 5.137001363416458e-06,
      "loss": 0.0003,
      "step": 18100
    },
    {
      "epoch": 0.7583235409322366,
      "grad_norm": 0.003664303570985794,
      "learning_rate": 5.093020187359811e-06,
      "loss": 0.0029,
      "step": 18150
    },
    {
      "epoch": 0.760412586499543,
      "grad_norm": 3.5153134376741946e-05,
      "learning_rate": 5.049039011303163e-06,
      "loss": 0.0012,
      "step": 18200
    },
    {
      "epoch": 0.7625016320668495,
      "grad_norm": 0.014297548681497574,
      "learning_rate": 5.005057835246515e-06,
      "loss": 0.0008,
      "step": 18250
    },
    {
      "epoch": 0.7645906776341559,
      "grad_norm": 3.308028681203723e-05,
      "learning_rate": 4.9610766591898675e-06,
      "loss": 0.0002,
      "step": 18300
    },
    {
      "epoch": 0.7666797232014624,
      "grad_norm": 1.9882934054749057e-07,
      "learning_rate": 4.917095483133219e-06,
      "loss": 0.0008,
      "step": 18350
    },
    {
      "epoch": 0.7687687687687688,
      "grad_norm": 0.0033846558071672916,
      "learning_rate": 4.873114307076572e-06,
      "loss": 0.0009,
      "step": 18400
    },
    {
      "epoch": 0.7708578143360753,
      "grad_norm": 2.882326407416258e-05,
      "learning_rate": 4.829133131019924e-06,
      "loss": 0.0025,
      "step": 18450
    },
    {
      "epoch": 0.7729468599033816,
      "grad_norm": 0.0002425869897706434,
      "learning_rate": 4.785151954963277e-06,
      "loss": 0.002,
      "step": 18500
    },
    {
      "epoch": 0.7750359054706881,
      "grad_norm": 0.004215606022626162,
      "learning_rate": 4.741170778906629e-06,
      "loss": 0.0019,
      "step": 18550
    },
    {
      "epoch": 0.7771249510379945,
      "grad_norm": 5.606734134744329e-07,
      "learning_rate": 4.6971896028499805e-06,
      "loss": 0.003,
      "step": 18600
    },
    {
      "epoch": 0.779213996605301,
      "grad_norm": 0.00016102538211271167,
      "learning_rate": 4.653208426793333e-06,
      "loss": 0.0019,
      "step": 18650
    },
    {
      "epoch": 0.7813030421726074,
      "grad_norm": 1.0157790711673442e-05,
      "learning_rate": 4.609227250736685e-06,
      "loss": 0.0002,
      "step": 18700
    },
    {
      "epoch": 0.7833920877399139,
      "grad_norm": 2.2479496237792773e-06,
      "learning_rate": 4.565246074680038e-06,
      "loss": 0.0001,
      "step": 18750
    },
    {
      "epoch": 0.7854811333072202,
      "grad_norm": 1.1042623100365745e-06,
      "learning_rate": 4.52126489862339e-06,
      "loss": 0.0001,
      "step": 18800
    },
    {
      "epoch": 0.7875701788745267,
      "grad_norm": 5.68191849126265e-09,
      "learning_rate": 4.478163346087875e-06,
      "loss": 0.001,
      "step": 18850
    },
    {
      "epoch": 0.7896592244418331,
      "grad_norm": 5.783409733339795e-07,
      "learning_rate": 4.434182170031227e-06,
      "loss": 0.0003,
      "step": 18900
    },
    {
      "epoch": 0.7917482700091396,
      "grad_norm": 0.00015039464051369578,
      "learning_rate": 4.39020099397458e-06,
      "loss": 0.002,
      "step": 18950
    },
    {
      "epoch": 0.793837315576446,
      "grad_norm": 2.241182528450736e-06,
      "learning_rate": 4.3462198179179315e-06,
      "loss": 0.0003,
      "step": 19000
    },
    {
      "epoch": 0.7959263611437525,
      "grad_norm": 3.0121152576612076e-06,
      "learning_rate": 4.302238641861284e-06,
      "loss": 0.0054,
      "step": 19050
    },
    {
      "epoch": 0.7980154067110589,
      "grad_norm": 2.311361640749965e-06,
      "learning_rate": 4.258257465804636e-06,
      "loss": 0.0,
      "step": 19100
    },
    {
      "epoch": 0.8001044522783654,
      "grad_norm": 3.3078986234613694e-06,
      "learning_rate": 4.214276289747988e-06,
      "loss": 0.0012,
      "step": 19150
    },
    {
      "epoch": 0.8021934978456717,
      "grad_norm": 1.0549848994401145e-08,
      "learning_rate": 4.170295113691341e-06,
      "loss": 0.0012,
      "step": 19200
    },
    {
      "epoch": 0.8042825434129782,
      "grad_norm": 2.9542459856202186e-07,
      "learning_rate": 4.126313937634693e-06,
      "loss": 0.0,
      "step": 19250
    },
    {
      "epoch": 0.8063715889802846,
      "grad_norm": 1.1504087638058991e-07,
      "learning_rate": 4.082332761578045e-06,
      "loss": 0.0022,
      "step": 19300
    },
    {
      "epoch": 0.8084606345475911,
      "grad_norm": 2.3851700348132e-07,
      "learning_rate": 4.038351585521397e-06,
      "loss": 0.0016,
      "step": 19350
    },
    {
      "epoch": 0.8105496801148975,
      "grad_norm": 3.0311919090308947e-06,
      "learning_rate": 3.994370409464749e-06,
      "loss": 0.0005,
      "step": 19400
    },
    {
      "epoch": 0.812638725682204,
      "grad_norm": 0.0001517395576229319,
      "learning_rate": 3.950389233408102e-06,
      "loss": 0.0034,
      "step": 19450
    },
    {
      "epoch": 0.8147277712495103,
      "grad_norm": 4.843150691158371e-06,
      "learning_rate": 3.906408057351454e-06,
      "loss": 0.0,
      "step": 19500
    },
    {
      "epoch": 0.8168168168168168,
      "grad_norm": 3.980780820711516e-05,
      "learning_rate": 3.8624268812948065e-06,
      "loss": 0.0026,
      "step": 19550
    },
    {
      "epoch": 0.8189058623841232,
      "grad_norm": 2.247710881420062e-06,
      "learning_rate": 3.818445705238158e-06,
      "loss": 0.0028,
      "step": 19600
    },
    {
      "epoch": 0.8209949079514297,
      "grad_norm": 1.0173432656301884e-06,
      "learning_rate": 3.7744645291815107e-06,
      "loss": 0.0007,
      "step": 19650
    },
    {
      "epoch": 0.8230839535187361,
      "grad_norm": 0.00017949184984900057,
      "learning_rate": 3.730483353124863e-06,
      "loss": 0.0,
      "step": 19700
    },
    {
      "epoch": 0.8251729990860426,
      "grad_norm": 1.0044058029734515e-07,
      "learning_rate": 3.6865021770682153e-06,
      "loss": 0.0028,
      "step": 19750
    },
    {
      "epoch": 0.827262044653349,
      "grad_norm": 9.883860002446454e-06,
      "learning_rate": 3.6425210010115676e-06,
      "loss": 0.0001,
      "step": 19800
    },
    {
      "epoch": 0.8293510902206555,
      "grad_norm": 0.0001476332836318761,
      "learning_rate": 3.5985398249549195e-06,
      "loss": 0.0003,
      "step": 19850
    },
    {
      "epoch": 0.8314401357879618,
      "grad_norm": 4.587997481930728e-10,
      "learning_rate": 3.554558648898272e-06,
      "loss": 0.0004,
      "step": 19900
    },
    {
      "epoch": 0.8335291813552683,
      "grad_norm": 8.642389730084687e-06,
      "learning_rate": 3.510577472841624e-06,
      "loss": 0.0014,
      "step": 19950
    },
    {
      "epoch": 0.8356182269225747,
      "grad_norm": 0.007234878372400999,
      "learning_rate": 3.4665962967849764e-06,
      "loss": 0.0004,
      "step": 20000
    }
  ],
  "logging_steps": 50,
  "max_steps": 23934,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
